# üìö Documenta√ß√£o Completa - Analisador Sint√°tico SLR(1)

## üìã √çndice
1. [Vis√£o Geral](#vis√£o-geral)
2. [Arquitetura do Sistema](#arquitetura-do-sistema)
3. [M√≥dulos e Fun√ß√µes](#m√≥dulos-e-fun√ß√µes)
4. [Exemplos de Uso](#exemplos-de-uso)
5. [Gram√°tica da Linguagem](#gram√°tica-da-linguagem)

---

## üéØ Vis√£o Geral

Este projeto implementa um **compilador completo em tr√™s fases** para uma linguagem de programa√ß√£o com sintaxe inspirada em Skyrim/Elder Scrolls:

1. **An√°lise L√©xica (Scanner)** - Tokeniza√ß√£o do c√≥digo fonte
2. **An√°lise Sint√°tica SLR(1)** - Valida√ß√£o da estrutura gramatical
3. **An√°lise Sem√¢ntica** - Verifica√ß√£o de tipos, escopos e tabela de s√≠mbolos

### Palavras-chave da Linguagem

| Palavra-chave | Significado | Exemplo |
|---------------|-------------|---------|
| `FUS` | Declara√ß√£o com atribui√ß√£o | `FUS x := 10` |
| `LOS` | Condicional (if) | `LOS x CMD` |
| `FOD ... FAH` | La√ßo while | `FOD CMD FAH EXPR` |
| `FAH ... FAH` | La√ßo for | `FAH CMD FAH EXPR` |
| `KEL` | M√≥dulo/namespace | `KEL player CMD` |
| `HON` | Input | `HON var` |
| `print` | Output | `print var` |
| `JUN` | Return | `JUN x` |
| `HIM` | This/self (acesso a membro) | `HIM . health` |
| `assign` | Atribui√ß√£o | `assign x := 5` |
| `NUST` | Nega√ß√£o l√≥gica (NOT) | `NUST x` |
| `ANRK` | E l√≥gico (AND) | `x ANRK y` |
| `AAN` | OU l√≥gico (OR) | `x AAN y` |
| `KO` | Pertencimento (IN) | `x KO y` |

---

## üèóÔ∏è Arquitetura do Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    C√ìDIGO FONTE                          ‚îÇ
‚îÇ           (Linguagem Fantasy - Skyrim Style)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         FASE 1: AN√ÅLISE L√âXICA (lexer.py)               ‚îÇ
‚îÇ  ‚Ä¢ Tokeniza√ß√£o                                           ‚îÇ
‚îÇ  ‚Ä¢ Identifica√ß√£o de palavras-chave                       ‚îÇ
‚îÇ  ‚Ä¢ Detec√ß√£o de erros l√©xicos                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ [Lista de Tokens]
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    FASE 2: AN√ÅLISE SINT√ÅTICA (parser_integrated.py)     ‚îÇ
‚îÇ  ‚Ä¢ Parsing SLR(1)                                        ‚îÇ
‚îÇ  ‚Ä¢ Valida√ß√£o de estrutura gramatical                     ‚îÇ
‚îÇ  ‚Ä¢ Stack e transi√ß√µes de estado                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ [√Årvore Sint√°tica]
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      FASE 3: AN√ÅLISE SEM√ÇNTICA (symbol_table.py)        ‚îÇ
‚îÇ  ‚Ä¢ Tabela de s√≠mbolos                                    ‚îÇ
‚îÇ  ‚Ä¢ Verifica√ß√£o de declara√ß√µes                            ‚îÇ
‚îÇ  ‚Ä¢ An√°lise de escopo                                     ‚îÇ
‚îÇ  ‚Ä¢ Detec√ß√£o de vari√°veis n√£o usadas                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
              ‚úÖ C√ìDIGO VALIDADO
```

---

## üì¶ M√≥dulos e Fun√ß√µes

### 1Ô∏è‚É£ **lexer.py** - Analisador L√©xico

#### Classe `TokenType`
Enumera√ß√£o com todos os tipos de tokens suportados.

```python
class TokenType(Enum):
    LOS = "LOS"      # if
    FOD = "FOD"      # while in√≠cio
    FAH = "FAH"      # separador
    # ... 23 tipos no total
```

#### Classe `Token`
Representa um token com seus atributos.

**Atributos:**
- `type`: Tipo do token (ex: "id", "num", "LOS")
- `lexeme`: Texto literal do token
- `line`: Linha no c√≥digo fonte
- `column`: Coluna no c√≥digo fonte
- `value`: Valor sem√¢ntico (para n√∫meros)

#### Classe `Lexer`

##### `__init__(self, source_code: str)`
**Descri√ß√£o:** Inicializa o analisador l√©xico com o c√≥digo fonte.

**L√≥gica:**
1. Armazena c√≥digo fonte na vari√°vel `self.source`
2. Inicializa ponteiro de posi√ß√£o (`self.position = 0`)
3. Configura rastreamento de linha e coluna
4. Cria listas vazias para tokens e erros

**Exemplo:**
```python
code = "FUS x := 10"
lexer = Lexer(code)
```

##### `current_char(self) -> str | None`
**Descri√ß√£o:** Retorna o caractere atual sem avan√ßar o ponteiro.

**L√≥gica:**
```python
if self.position >= len(self.source):
    return None
return self.source[self.position]
```

**Sa√≠da:** Caractere na posi√ß√£o atual ou `None` se fim do arquivo.

##### `advance(self)`
**Descri√ß√£o:** Avan√ßa o ponteiro para o pr√≥ximo caractere e atualiza linha/coluna.

**L√≥gica:**
1. Se caractere √© `\n`: incrementa linha, reseta coluna
2. Caso contr√°rio: incrementa coluna
3. Incrementa posi√ß√£o

##### `skip_whitespace(self)`
**Descri√ß√£o:** Pula espa√ßos em branco, tabs e quebras de linha.

**L√≥gica:**
```python
while current_char() in ' \t\n\r':
    advance()
```

##### `skip_comment(self) -> bool`
**Descri√ß√£o:** Pula coment√°rios de linha (#) e bloco (/* */).

**L√≥gica:**
- **Coment√°rio de linha:** `# texto at√© \n`
  - Avan√ßa at√© encontrar `\n`
- **Coment√°rio de bloco:** `/* texto */`
  - Avan√ßa at√© encontrar `*/`
  - Gera erro se n√£o fechado

**Retorna:** `True` se pulou coment√°rio, `False` caso contr√°rio.

**Exemplo:**
```python
# Este √© um coment√°rio de linha
FUS x := 10  /* coment√°rio de bloco */
```

##### `read_number(self) -> Token`
**Descri√ß√£o:** L√™ uma sequ√™ncia de d√≠gitos e cria token num√©rico.

**L√≥gica:**
1. Coleta todos os d√≠gitos consecutivos
2. Converte string para inteiro
3. Cria token do tipo `NUM`

**Entrada:** `"123abc"`
**Sa√≠da:** `Token(NUM, "123", linha, coluna, 123)`

##### `read_identifier_or_keyword(self) -> Token`
**Descri√ß√£o:** L√™ identificador ou palavra-chave.

**L√≥gica:**
1. Coleta caracteres alfanum√©ricos e underscore
2. Verifica se texto est√° no dicion√°rio `KEYWORDS`
3. Se sim: retorna token de palavra-chave
4. Se n√£o: retorna token `ID`

**Exemplo:**
```python
# Entrada: "LOS"
# Sa√≠da: Token(LOS, "LOS", 1, 1, "LOS")

# Entrada: "health"
# Sa√≠da: Token(id, "health", 1, 1, "health")
```

##### `read_operator(self) -> Token | None`
**Descri√ß√£o:** L√™ operadores e pontua√ß√£o.

**L√≥gica:**
- Operador composto `:=`: verifica dois caracteres
- Operadores simples: `+`, `-`, `;`, `.`, `(`, `)`

**Exemplo:**
```python
# Entrada: ":="
# Sa√≠da: Token(":=", ":=", 1, 1, ":=")
```

##### `tokenize(self) -> List[Token]`
**Descri√ß√£o:** **Fun√ß√£o principal** - Converte c√≥digo fonte em lista de tokens.

**Algoritmo:**
```
ENQUANTO n√£o chegou ao fim do arquivo:
    1. Pular espa√ßos em branco
    2. Pular coment√°rios
    3. Tentar ler n√∫mero
    4. Tentar ler identificador/palavra-chave
    5. Tentar ler operador
    6. Se nenhum caso: gerar erro l√©xico
    
ADICIONAR token EOF ($) no final
RETORNAR lista de tokens
```

**Exemplo completo:**
```python
code = """
FUS health := 100
assign health := health - 10
JUN health
"""

lexer = Lexer(code)
tokens = lexer.tokenize()

# Resultado:
# [
#   Token(FUS, "FUS", 2, 1),
#   Token(id, "health", 2, 5),
#   Token(:=, ":=", 2, 12),
#   Token(num, "100", 2, 15, 100),
#   Token(assign, "assign", 3, 1),
#   ...
#   Token($, "$", 5, 1)
# ]
```

##### `print_tokens(self)`
**Descri√ß√£o:** Imprime tabela formatada de tokens.

**Sa√≠da:**
```
================================================================================
FITA DE TOKENS
================================================================================
#     Tipo            Lexema               Linha    Coluna   Valor
--------------------------------------------------------------------------------
1     FUS             FUS                  1        1        FUS
2     id              health               1        5        health
3     :=              :=                   1        12       :=
4     num             100                  1        15       100
5     $               $                    1        19       $
================================================================================
Total de tokens: 5
```

##### `has_errors(self) -> bool`
**Descri√ß√£o:** Verifica se houve erros l√©xicos.

**Retorna:** `True` se `len(self.errors) > 0`

##### `print_errors(self)`
**Descri√ß√£o:** Imprime erros l√©xicos formatados.

**Exemplo de sa√≠da:**
```
================================================================================
ERROS L√âXICOS
================================================================================
  ‚úó ERRO L√âXICO (Linha 3, Coluna 15): Caractere inv√°lido '@'
  ‚úó ERRO L√âXICO (Linha 5, Coluna 1): Coment√°rio de bloco n√£o fechado
================================================================================
```

---

### 2Ô∏è‚É£ **parser_integrated.py** - Analisador Sint√°tico SLR(1)

#### Classe `Token`
Mesma estrutura do lexer, usada para representar tokens com atributos sem√¢nticos.

#### Classe `SemanticError`
Exce√ß√£o personalizada para erros sem√¢nticos.

**Atributos:**
- `message`: Mensagem de erro
- `line`: Linha do erro
- `column`: Coluna do erro
- `error_type`: Tipo do erro (ex: "SEMANTIC")

#### Classe `SLRParserWithSemantics`

##### `__init__(self, verbose=True)`
**Descri√ß√£o:** Inicializa o parser com an√°lise sem√¢ntica integrada.

**Atributos inicializados:**
- `stack`: Pilha de estados (inicia com [0])
- `symbols`: Pilha de s√≠mbolos sint√°ticos
- `attributes`: Pilha de atributos sem√¢nticos
- `symbol_table`: Tabela de s√≠mbolos (inst√¢ncia de `SymbolTable`)
- `closures`: Closures LR(0) importados de `SLR.py`
- `transitions`: Tabela GOTO importada de `goto.py`
- `follow`: Conjuntos FOLLOW importados de `follow.py`

**L√≥gica:**
```python
self.stack = [0]              # Estado inicial
self.symbols = []             # Vazia
self.attributes = []          # Vazia
self.symbol_table = SymbolTable()
```

##### `_extract_productions(self) -> dict`
**Descri√ß√£o:** Extrai produ√ß√µes gramaticais dos closures.

**L√≥gica:**
1. Percorre todos os estados nos closures
2. Identifica produ√ß√µes completas (ponto no final)
3. Armazena no formato `{estado: (lhs, [rhs])}`

**Exemplo:**
```python
# Closure 11: ["IO -> HON."]
# Produ√ß√£o extra√≠da:
productions[11] = ("IO", ["HON"])
```

##### `semantic_action(self, production_lhs, production_rhs, attributes) -> Any`
**Descri√ß√£o:** **FUN√á√ÉO CENTRAL** - Executa a√ß√µes sem√¢nticas durante redu√ß√µes.

**L√≥gica por tipo de produ√ß√£o:**

**1. FUS id := EXPR (Declara√ß√£o)**
```python
if production_lhs == "CMD" and len(production_rhs) == 4:
    if production_rhs[0] == "FUS":
        var_token = attributes[1]      # Token do identificador
        expr_value = attributes[3]     # Valor da express√£o
        
        # DECLARA na tabela de s√≠mbolos
        self.symbol_table.declare(
            var_token.lexeme,
            symbol_type="variable",
            line=var_token.line,
            value=expr_value
        )
        
        return {"type": "declaration", "name": var_token.lexeme, "value": expr_value}
```

**Exemplo:**
```python
# C√≥digo: FUS health := 100
# A√ß√£o: Declara 'health' com valor 100 no escopo atual
```

**2. assign id := EXPR (Atribui√ß√£o)**
```python
if production_lhs == "CMD" and production_rhs[1] == ":=":
    lhs_info = attributes[0]       # Informa√ß√µes do LHS
    expr_value = attributes[2]     # Novo valor
    
    # VERIFICA se vari√°vel foi declarada
    symbol = self.symbol_table.lookup(var_name, line=var_line)
    if symbol:
        symbol.value = expr_value  # Atualiza valor
```

**Exemplo:**
```python
# C√≥digo: assign health := 50
# A√ß√£o: Verifica se 'health' existe e atualiza para 50
```

**3. KEL id CMD (M√≥dulo)**
```python
if production_lhs == "CMD" and production_rhs[0] == "KEL":
    module_token = attributes[1]
    
    # ENTRA em novo escopo
    self.symbol_table.enter_scope(f"KEL_{module_token.lexeme}")
    
    # DECLARA m√≥dulo
    self.symbol_table.declare(
        module_token.lexeme,
        symbol_type="module",
        line=module_token.line
    )
```

**Exemplo:**
```python
# C√≥digo: KEL player FUS health := 100
# A√ß√£o: Cria escopo "KEL_player" e declara 'health' dentro dele
```

**4. FACTOR -> id (Uso de vari√°vel)**
```python
if production_lhs == "FACTOR" and production_rhs[0] == "id":
    id_token = attributes[0]
    
    # BUSCA na tabela de s√≠mbolos
    symbol = self.symbol_table.lookup(id_token.lexeme, line=id_token.line)
    
    if symbol:
        return symbol.value  # Retorna valor armazenado
    else:
        # ERRO: vari√°vel n√£o declarada
```

**Exemplo:**
```python
# C√≥digo: JUN health
# A√ß√£o: Busca 'health' na tabela, retorna erro se n√£o encontrada
```

**5. EXPR -> TERM EXPR' (Express√£o aritm√©tica)**
```python
if production_lhs == "EXPR":
    term_value = attributes[0]
    expr_prime = attributes[1]
    
    if expr_prime and "op" in expr_prime:
        # S√≠ntese: combina termo e operador
        return f"({term_value} {expr_prime['op']} {expr_prime['right']})"
    else:
        return term_value
```

**Exemplo:**
```python
# C√≥digo: 10 + 20 - 5
# S√≠ntese: "(10 + (20 - 5))"
```

##### `parse(self, tokens: List[Token]) -> bool`
**Descri√ß√£o:** **FUN√á√ÉO PRINCIPAL** - Realiza parsing SLR(1) com an√°lise sem√¢ntica.

**Algoritmo completo:**
```
INICIALIZAR:
    stack = [0]
    token_index = 0
    current_token = tokens[0]

LOOP INFINITO:
    state = stack[-1]
    lookahead = current_token.type
    
    # CASO 1: ACEITA√á√ÉO
    SE state == 1 E lookahead == "$":
        Verificar s√≠mbolos n√£o usados
        RETORNAR sucesso
    
    # CASO 2: SHIFT
    SE (state, lookahead) ‚àà transitions:
        next_state = transitions[(state, lookahead)]
        Empilhar: state, symbol, attribute
        Avan√ßar para pr√≥ximo token
        CONTINUAR
    
    # CASO 3: EPSILON TRANSITION
    SE (state, "epsilon") ‚àà transitions:
        Tratar EXPR' -> Œµ
        Fazer GOTO
        CONTINUAR
    
    # CASO 4: REDUCE
    SE state tem produ√ß√£o E lookahead ‚àà FOLLOW(lhs):
        lhs, rhs = productions[state]
        
        # Coletar atributos
        prod_attributes = attributes[-len(rhs):]
        
        # EXECUTAR A√á√ÉO SEM√ÇNTICA
        synthesized = semantic_action(lhs, rhs, prod_attributes)
        
        # Desempilhar s√≠mbolos
        POP len(rhs) s√≠mbolos da pilha
        
        # GOTO
        state_after = stack[-1]
        goto_state = transitions[(state_after, lhs)]
        
        Empilhar: goto_state, lhs, synthesized
        CONTINUAR
    
    # CASO 5: ERRO SINT√ÅTICO
    Registrar erro
    RETORNAR False
```

**Exemplo de execu√ß√£o:**

```python
# C√≥digo: FUS x := 10

tokens = [
    Token("FUS", "FUS", 1),
    Token("id", "x", 1),
    Token(":=", ":=", 1),
    Token("num", "10", 1, value=10),
    Token("$", "$", 1)
]

parser = SLRParserWithSemantics(verbose=True)
sucesso = parser.parse(tokens)

# Sa√≠da (verbose):
# Passo 1: Stack=[0], Estado=0, Token=FUS
#   SHIFT -> 10
# 
# Passo 2: Stack=[0, 10], Estado=10, Token=id
#   SHIFT -> 27
#
# Passo 3: Stack=[0, 10, 27], Estado=27, Token=:=
#   SHIFT -> 51
#
# Passo 4: Stack=[0, 10, 27, 51], Estado=51, Token=num
#   SHIFT -> 22
#
# Passo 5: Stack=[0, 10, 27, 51, 22], Estado=22, Token=$
#   REDUCE FACTOR -> num
#   [Sem√¢ntico] Valor: 10
#   GOTO(51, FACTOR) = 19
#
# ... (continua at√© aceita√ß√£o)
#
# [OK] ANALISE SINTATICA ACEITA!
```

##### `has_errors(self) -> bool`
**Descri√ß√£o:** Verifica se h√° erros sint√°ticos ou sem√¢nticos.

**L√≥gica:**
```python
return len(self.errors) > 0 or self.symbol_table.has_errors()
```

##### `print_report(self)`
**Descri√ß√£o:** Imprime relat√≥rio completo com erros, avisos e tabela de s√≠mbolos.

**Sa√≠da:**
```
======================================================================
RELATORIO DE ANALISE
======================================================================

[X] ERROS ENCONTRADOS:
  - ERRO SINTATICO (Linha 3): Token inesperado 'num'
  - Erro sem√¢ntico (linha 5): 'y' n√£o foi declarado

[!] AVISOS:
  - Aviso (linha 2): vari√°vel 'z' declarada mas n√£o usada

======================================================================
TABELA DE SIMBOLOS
======================================================================
Escopo: global
  [‚úì] health: variable
  [ ] z: variable
  Escopo: KEL_player
    [‚úì] strength: variable
======================================================================
```

##### `reset(self)`
**Descri√ß√£o:** Reinicia o parser para nova an√°lise.

**L√≥gica:**
```python
self.stack = [0]
self.symbols = []
self.attributes = []
self.symbol_table = SymbolTable()
self.errors = []
self.warnings = []
```

---

### 3Ô∏è‚É£ **symbol_table.py** - Tabela de S√≠mbolos

#### Classe `Symbol`
**Descri√ß√£o:** Representa um identificador na tabela de s√≠mbolos.

**Atributos:**
- `name`: Nome do identificador (ex: "health")
- `symbol_type`: Tipo ("variable", "module", "parameter")
- `scope`: Escopo onde foi declarado (ex: "global")
- `line`: Linha de declara√ß√£o
- `value`: Valor atribu√≠do (opcional)
- `used`: Boolean - marca se foi referenciado no c√≥digo

**Exemplo:**
```python
symbol = Symbol(
    name="health",
    symbol_type="variable",
    scope="global",
    line=1,
    value=100
)
```

#### Classe `Scope`
**Descri√ß√£o:** Representa um escopo (bloco de c√≥digo).

**Atributos:**
- `name`: Nome do escopo (ex: "global", "KEL_player")
- `parent`: Escopo pai (para aninhamento)
- `symbols`: Dicion√°rio `{nome: Symbol}`
- `children`: Lista de escopos filhos

##### `define(self, symbol: Symbol) -> bool`
**Descri√ß√£o:** Define um novo s√≠mbolo neste escopo.

**L√≥gica:**
```python
if symbol.name in self.symbols:
    return False  # J√° existe (erro de redeclara√ß√£o)
self.symbols[symbol.name] = symbol
return True
```

##### `lookup(self, name: str, recursive=True) -> Symbol | None`
**Descri√ß√£o:** Procura s√≠mbolo neste escopo (e nos pais se recursive=True).

**Algoritmo:**
```
SE nome ‚àà symbols deste escopo:
    RETORNAR symbol
    
SE recursive E h√° escopo pai:
    RETORNAR parent.lookup(name, recursive=True)
    
RETORNAR None (n√£o encontrado)
```

**Exemplo:**
```python
# Escopo: KEL_player (filho de global)
# global: {x: Symbol("x")}
# KEL_player: {health: Symbol("health")}

# Busca 'health' em KEL_player
scope.lookup("health")        # ‚úì Retorna Symbol("health")

# Busca 'x' em KEL_player (recursiva)
scope.lookup("x", recursive=True)  # ‚úì Encontra em global

# Busca 'mana' (n√£o existe)
scope.lookup("mana")          # ‚úó Retorna None
```

#### Classe `SymbolTable`

##### `__init__(self)`
**Descri√ß√£o:** Inicializa tabela com escopo global.

**Estrutura:**
```python
self.global_scope = Scope("global")
self.current_scope = self.global_scope
self.errors = []
self.warnings = []
```

##### `enter_scope(self, scope_name: str) -> Scope`
**Descri√ß√£o:** Entra em novo escopo (cria escopo filho).

**L√≥gica:**
```python
new_scope = Scope(scope_name, parent=self.current_scope)
self.current_scope.children.append(new_scope)
self.current_scope = new_scope
return new_scope
```

**Exemplo:**
```python
st = SymbolTable()
# Escopo atual: global

st.enter_scope("KEL_player")
# Escopo atual: KEL_player (filho de global)
```

##### `exit_scope(self)`
**Descri√ß√£o:** Sai do escopo atual, voltando ao pai.

**L√≥gica:**
```python
if self.current_scope.parent:
    self.current_scope = self.current_scope.parent
```

##### `declare(self, name, symbol_type='variable', line=None, value=None) -> bool`
**Descri√ß√£o:** **FUN√á√ÉO CHAVE** - Declara novo s√≠mbolo no escopo atual.

**Algoritmo:**
```
CRIAR Symbol(name, symbol_type, current_scope.name, line, value)

SE current_scope.define(symbol) falhar:
    ADICIONAR erro: "'{name}' j√° foi declarado em '{current_scope.name}'"
    RETORNAR False

RETORNAR True
```

**Exemplo:**
```python
st = SymbolTable()

# Declara√ß√£o bem-sucedida
st.declare("health", "variable", line=1, value=100)  # ‚úì True

# Redeclara√ß√£o (erro)
st.declare("health", "variable", line=3, value=50)   # ‚úó False
# Erro: "Erro sem√¢ntico (linha 3): 'health' j√° foi declarado em 'global'"
```

##### `lookup(self, name, line=None, mark_used=True) -> Symbol | None`
**Descri√ß√£o:** Busca s√≠mbolo (marca como usado se encontrado).

**L√≥gica:**
```python
symbol = self.current_scope.lookup(name, recursive=True)

if symbol is None:
    self.errors.append(f"Erro sem√¢ntico (linha {line}): '{name}' n√£o foi declarado")
    return None

if mark_used:
    symbol.used = True  # Marca como referenciado

return symbol
```

**Exemplo:**
```python
# Declara√ß√£o: FUS x := 10
st.declare("x", "variable", line=1, value=10)

# Uso: JUN x
symbol = st.lookup("x", line=3)  # ‚úì Retorna Symbol, marca como usado

# Uso de vari√°vel n√£o declarada
st.lookup("y", line=5)  # ‚úó Retorna None, gera erro
```

##### `check_unused_symbols(self)`
**Descri√ß√£o:** Verifica s√≠mbolos declarados mas nunca usados.

**Algoritmo:**
```
PARA CADA escopo (recursivamente):
    PARA CADA symbol em escopo.symbols:
        SE symbol.used == False E symbol.type == "variable":
            ADICIONAR warning: "vari√°vel '{name}' declarada mas n√£o usada"
```

**Exemplo:**
```python
# C√≥digo:
# FUS x := 10
# FUS y := 20
# JUN x

st.check_unused_symbols()
# Aviso: "Aviso (linha 2): vari√°vel 'y' declarada mas n√£o usada"
```

##### `print_table(self, scope=None, indent=0)`
**Descri√ß√£o:** Imprime tabela de s√≠mbolos hier√°rquica.

**Sa√≠da:**
```
Escopo: global
  [‚úì] x: variable
  [ ] y: variable
  Escopo: KEL_player
    [‚úì] health: variable
    [‚úì] strength: variable
```

##### `has_errors(self) -> bool`
**Descri√ß√£o:** Verifica se h√° erros sem√¢nticos.

##### `print_errors(self)`
**Descri√ß√£o:** Imprime erros e avisos formatados.

---

### 4Ô∏è‚É£ **main.py** - Pipeline Completo (PDA + SLR)

#### Classe `PDALexerAdapter`
**Descri√ß√£o:** Adapta o Aut√¥mato de Pilha (PDA) para funcionar como analisador l√©xico.

##### Mapeamento de Estados para Tokens
```python
STATE_TO_TOKEN = {
    'E11,Z': 'KEL',      # Reconheceu palavra "KEL"
    'D10,Z': 'LOS',      # Reconheceu palavra "LOS"
    'E12,Z': 'FOD',      # Reconheceu palavra "FOD"
    'D3,Z': 'FAH',       # Reconheceu palavra "FAH"
    'D5,Z': 'FUS',       # Reconheceu palavra "FUS"
    # ... 13 mapeamentos total
}
```

##### `__init__(self)`
**Descri√ß√£o:** Inicializa PDA com alfabeto e estados finais.

**L√≥gica:**
```python
Q = ['A1,B2,Z', 'Z', 'B7,B8,Z', ...]  # 36 estados
Sigma = ['#', 'K', 'O', 'E', 'L', ...]  # 18 s√≠mbolos
gama = ['$', 'K', 'O', 'E', 'L', ...]   # Alfabeto de pilha
F = ['E11,Z', 'D10,Z', ...]             # 13 estados finais

self.pda = AP(Sigma, gama, DeltaFinal, 'S', F)
```

##### `tokenize(self, source_code: str) -> List[Token]`
**Descri√ß√£o:** **FUN√á√ÉO PRINCIPAL** - Processa c√≥digo via PDA e gera tokens.

**Algoritmo:**
```
SEPARAR c√≥digo por '#' (quebras de linha)

PARA CADA linha:
    SEPARAR linha por espa√ßos (palavras)
    
    PARA CADA palavra:
        estado_final = _reconhecer_palavra(palavra)
        
        SE estado_final ‚àà STATE_TO_TOKEN:
            token_type = STATE_TO_TOKEN[estado_final]
            CRIAR Token(token_type, palavra, linha)
        
        SEN√ÉO SE estado_final == 'X':
            # Palavra rejeitada pelo PDA
            token = _classificar_palavra_desconhecida(palavra)
        
        SEN√ÉO:
            # Estado n√£o mapeado, tratar como ID
            CRIAR Token("id", palavra, linha)

ADICIONAR Token("$", "$", linha_final)  # EOF
RETORNAR tokens
```

**Exemplo:**
```python
adapter = PDALexerAdapter()
code = "KEL player # FUS health := 100"
tokens = adapter.tokenize(code)

# Sa√≠da do PDA:
# [OK] Linha 1: 'KEL' -> Estado E11,Z -> KEL (ACEITO)
# [OK] Linha 1: 'player' -> N√£o reconhecido pelo PDA -> id
# [OK] Linha 2: 'FUS' -> Estado D5,Z -> FUS (ACEITO)
# [OK] Linha 2: 'health' -> N√£o reconhecido pelo PDA -> id
# ...
```

##### `_reconhecer_palavra(self, palavra: str) -> str`
**Descri√ß√£o:** Simula execu√ß√£o do PDA para reconhecer palavra.

**Algoritmo:**
```
estado = 'S'  # Estado inicial

PARA CADA caractere em palavra:
    SE caractere ‚àâ Sigma:
        RETORNAR 'X'  # Rejeitar
    
    transicao = delta[(estado, caractere, EPSILON)]
    
    SE transicao existe:
        estado = transicao[0]
    SEN√ÉO:
        RETORNAR 'X'  # Sem transi√ß√£o

SE estado ‚àà estados_finais:
    RETORNAR estado
SEN√ÉO:
    RETORNAR 'X'
```

**Exemplo:**
```python
# Palavra: "KEL"
# Caminho: S -> (K) -> B1,B2,Z -> (E) -> C2,Z -> (L) -> E11,Z (ACEITO)

# Palavra: "health"
# Caminho: S -> (h) -> Z -> (e) -> Z -> ... -> Z (N√ÉO FINAL) -> X
```

##### `_classificar_palavra_desconhecida(self, palavra: str, linha: int) -> Token`
**Descri√ß√£o:** Classifica palavras n√£o reconhecidas pelo PDA.

**L√≥gica:**
1. Se todos caracteres s√£o d√≠gitos ‚Üí `Token(NUM)`
2. Se √© operador (`:=`, `;`, etc.) ‚Üí `Token(OPERADOR)`
3. Se √© palavra-chave extra (`assign`, `print`) ‚Üí `Token(KEYWORD)`
4. Padr√£o ‚Üí `Token(ID)`

#### Classe `CompiladorCompleto`

##### `__init__(self, verbose=True)`
**Descri√ß√£o:** Inicializa pipeline completo.

```python
self.lexer = PDALexerAdapter()
self.parser = SLRParserWithSemantics(verbose=verbose)
```

##### `compile(self, source_code: str) -> bool`
**Descri√ß√£o:** **FUN√á√ÉO PRINCIPAL** - Executa compila√ß√£o em 3 fases.

**Fluxo completo:**
```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë              FASE 1: AN√ÅLISE L√âXICA (PDA)                  ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    ‚Üì [Processa cada palavra pelo PDA]
    ‚Üì [Gera lista de tokens]
    
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë        FASE 2 & 3: SINT√ÅTICA + SEM√ÇNTICA (SLR)            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    ‚Üì [Parser SLR valida estrutura]
    ‚Üì [A√ß√µes sem√¢nticas atualizam tabela de s√≠mbolos]
    ‚Üì [Verifica declara√ß√µes e escopos]
    
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                   RELAT√ìRIO FINAL                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    ‚Üì [Imprime erros/avisos]
    ‚Üì [Mostra tabela de s√≠mbolos]
```

**Exemplo:**
```python
compilador = CompiladorCompleto(verbose=True)
code = "FUS health := 100 ; JUN health"
sucesso = compilador.compile(code)

# Sa√≠da:
# ==================================================================
# =          SA√çDA DO PDA (Compiladores/main.py)                  =
# ==================================================================
# [OK] Linha 1: 'FUS' -> Estado D5,Z -> FUS (ACEITO)
# [OK] Linha 1: 'health' -> N√£o reconhecido pelo PDA -> id
# ...
# 
# ==================================================================
# =              TOKENS GERADOS PARA O PARSER                      =
# ==================================================================
# 1. Token(FUS, 'FUS', L1)
# 2. Token(id, 'health', L1)
# ...
#
# === Analise Sintatica e Semantica SLR(1) ===
# [Sem√¢ntico] Declarando 'health' = 100 (linha 1)
# ...
# [OK] ANALISE SINTATICA ACEITA!
#
# ======================================================================
# RELATORIO DE ANALISE
# ======================================================================
# [OK] Nenhum erro encontrado
```

---

### 5Ô∏è‚É£ **SLR.py, goto.py, first.py, follow.py** - Tabelas do Parser

#### **SLR.py** - Closures LR(0)
**Descri√ß√£o:** Define 60 closures (estados) do aut√¥mato SLR(1).

**Estrutura:**
```python
closures = {
    0: {  # Estado inicial
        ("S'", (".", "S")),
        ("S", (".", "CMD", ";", "S")),
        ("CMD", (".", "LOS", "EXPR", "CMD")),
        # ... 15 itens LR(0)
    },
    
    11: ["IO -> HON."],  # Estado de redu√ß√£o
    12: ["IO -> print."],
    # ...
}
```

**L√≥gica:**
- Estados 0-10: Formato tupla com m√∫ltiplos itens (kernel + closure)
- Estados 11-59: Formato string com produ√ß√µes prontas para redu√ß√£o

**Exemplo de uso:**
```python
# No parser:
if state in self.productions:
    lhs, rhs = self.productions[state]
    # state=11 ‚Üí lhs="IO", rhs=["HON"]
```

#### **goto.py** - Tabela de Transi√ß√µes
**Descri√ß√£o:** 200+ entradas mapeando `(estado, s√≠mbolo) ‚Üí pr√≥ximo_estado`.

**Estrutura:**
```python
transitions = {
    (0, "S"): 1,       # Do estado 0, com 'S' vai para estado 1
    (0, "CMD"): 2,     # Do estado 0, com 'CMD' vai para estado 2
    (0, "LOS"): 3,     # Do estado 0, com 'LOS' vai para estado 3
    # ... 200+ transi√ß√µes
}
```

**Uso em SHIFT:**
```python
if (state, lookahead) in transitions:
    next_state = transitions[(state, lookahead)]
    stack.append(next_state)
```

**Uso em GOTO:**
```python
# Ap√≥s redu√ß√£o para n√£o-terminal 'lhs'
state_after_pop = stack[-1]
if (state_after_pop, lhs) in transitions:
    goto_state = transitions[(state_after_pop, lhs)]
    stack.append(goto_state)
```

#### **first.py** - Conjuntos FIRST
**Descri√ß√£o:** FIRST sets para cada n√£o-terminal (usado para parsing preditivo).

```python
FIRST = {
    "S'": {"LOS","FOD","FAH","JUN","KEL","FUS","HON","print","assign","HIM"},
    "EXPR": {"NUST","id","num","HIM","("},
    "EXPR'": {"Œµ","+","-","ANRK","AAN","KO"},
    # ...
}
```

**Interpreta√ß√£o:**
- `FIRST["EXPR"]`: Conjunto de tokens que podem iniciar uma express√£o
- `"Œµ"` indica que pode derivar vazio (epsilon)

#### **follow.py** - Conjuntos FOLLOW
**Descri√ß√£o:** FOLLOW sets para cada n√£o-terminal (usado para decidir redu√ß√µes).

```python
FOLLOW = {
    "S'": {"$"},
    "CMD": {";","$","FAH"},
    "EXPR": {"LOS","FOD","FAH","JUN","KEL",";","$",")"},
    # ...
}
```

**Uso no parser:**
```python
if state in self.productions:
    lhs, rhs = self.productions[state]
    
    # Reduz se lookahead est√° em FOLLOW(lhs)
    if lookahead in self.follow.get(lhs, set()):
        # Executar redu√ß√£o
```

---

### 6Ô∏è‚É£ **Compiladores/** - Aut√¥mato de Pilha (PDA)

#### **pda.py** - Classe `AP`

##### `__init__(self, Sigma, gama, delta, q0, F)`
**Descri√ß√£o:** Inicializa aut√¥mato de pilha.

**Par√¢metros:**
- `Sigma`: Alfabeto de entrada (caracteres)
- `gama`: Alfabeto de pilha
- `delta`: Fun√ß√£o de transi√ß√£o (dicion√°rio)
- `q0`: Estado inicial
- `F`: Estados finais

##### `run(self, entrada: str) -> bool`
**Descri√ß√£o:** Executa PDA na entrada e retorna se aceita.

**Algoritmo:**
```
SEPARAR entrada por '#' (linhas)

PARA CADA linha:
    PARA CADA palavra:
        estado = q0  # Reset para cada palavra
        
        PARA CADA caractere em palavra:
            transicao = delta[(estado, caractere, EPSILON)]
            
            SE transicao existe:
                estado = transicao[0]
            SEN√ÉO:
                estado = 'X'  # Rejeitar
                BREAK
        
        SE estado ‚àâ estados_finais:
            estado = 'X'
        
        ADICIONAR caminho √† FITA
        ADICIONAR (linha, estado, palavra) √† TS

RETORNAR True SE todos estados finais v√°lidos
```

**Exemplo:**
```python
pda = AP(Sigma, gama, DeltaFinal, 'S', F)
entrada = "KEL # FOD"
resultado = pda.run(entrada)

# Sa√≠da:
# ==================================================
# FITA (Caminhos Completos): ['S -> B1,B2,Z -> C2,Z -> E11,Z', 'S -> B5,B7,B9,Z -> Z -> D5,Z']
# 
# Tabela de Simbolos (TS):
#   1. Linha 1: 'KEL' -> E11,Z
#   2. Linha 2: 'FOD' -> D5,Z
```

#### **delta.py** - `DeltaFinal`
**Descri√ß√£o:** Dicion√°rio com 687 transi√ß√µes do PDA.

```python
DeltaFinal = {
    ('S', 'K', EPSILON): ('B1,B2,Z', 'K'),
    ('S', 'L', EPSILON): ('B7,B8,Z', 'L'),
    # ... 687 transi√ß√µes
}
```

**Formato:** `(estado_atual, s√≠mbolo_entrada, topo_pilha) : (pr√≥ximo_estado, s√≠mbolo_pilha)`

#### **constants.py**
```python
EPSILON = None  # Representa s√≠mbolo vazio
```

---

## üìù Exemplos de Uso Completos

### Exemplo 1: Declara√ß√£o Simples

**C√≥digo:**
```fantasy
FUS health := 100
```

**Execu√ß√£o:**
```python
from lexer import Lexer
from parser_integrated import SLRParserWithSemantics

# Fase 1: L√©xico
lexer = Lexer("FUS health := 100")
tokens = lexer.tokenize()
# [Token(FUS), Token(id, "health"), Token(:=), Token(num, "100", value=100), Token($)]

# Fase 2 & 3: Sint√°tico + Sem√¢ntico
parser = SLRParserWithSemantics(verbose=True)
sucesso = parser.parse(tokens)

# Resultado:
# [Sem√¢ntico] Declarando 'health' = 100 (linha 1)
# [OK] ANALISE SINTATICA ACEITA!
#
# Tabela de S√≠mbolos:
# Escopo: global
#   [‚úì] health: variable (valor=100)
```

### Exemplo 2: Sequ√™ncia de Comandos

**C√≥digo:**
```fantasy
FUS x := 10 ; FUS y := 20 ; assign x := x + y
```

**An√°lise:**
1. **L√©xico:** Gera 13 tokens
2. **Sint√°tico:** Valida estrutura `CMD ; CMD ; CMD`
3. **Sem√¢ntico:**
   - Declara `x = 10`
   - Declara `y = 20`
   - Verifica se `x` e `y` existem
   - Atualiza `x = (10 + 20)`

**Tabela de S√≠mbolos Final:**
```
global:
  [‚úì] x: variable (valor=30)
  [‚úì] y: variable (valor=20)
```

### Exemplo 3: M√≥dulo KEL

**C√≥digo:**
```fantasy
KEL player FUS strength := 50
```

**An√°lise Sem√¢ntica:**
```python
# 1. Parser encontra "KEL player"
symbol_table.enter_scope("KEL_player")

# 2. Declara m√≥dulo
symbol_table.declare("player", symbol_type="module", line=1)

# 3. Dentro do escopo, declara strength
symbol_table.declare("strength", symbol_type="variable", line=1, value=50)

# 4. Ao sair do m√≥dulo
symbol_table.exit_scope()
```

**Estrutura de Escopos:**
```
global:
  [‚úì] player: module
    KEL_player:
      [‚úì] strength: variable (valor=50)
```

### Exemplo 4: Erro Sem√¢ntico - Vari√°vel N√£o Declarada

**C√≥digo:**
```fantasy
assign mana := 100
```

**Resultado:**
```
[X] ERROS ENCONTRADOS:
  - Erro sem√¢ntico (linha 1): 'mana' n√£o foi declarado

TABELA DE SIMBOLOS
Escopo: global
  (vazia)
```

**Explica√ß√£o:** Tentou atribuir valor a `mana` sem declar√°-la primeiro com `FUS`.

### Exemplo 5: Aviso - Vari√°vel N√£o Usada

**C√≥digo:**
```fantasy
FUS unused_var := 10 ; FUS x := 20 ; JUN x
```

**Resultado:**
```
[OK] Nenhum erro encontrado

[!] AVISOS:
  - Aviso (linha 1): vari√°vel 'unused_var' declarada mas n√£o usada

TABELA DE SIMBOLOS
Escopo: global
  [ ] unused_var: variable
  [‚úì] x: variable
```

### Exemplo 6: Express√£o Aritm√©tica Complexa

**C√≥digo:**
```fantasy
FUS result := 10 + 20 - 5
```

**S√≠ntese de Atributos:**
```
FACTOR -> num (10)       ‚Üí atributo: 10
TERM -> FACTOR           ‚Üí atributo: 10
OP -> +                  ‚Üí atributo: "+"
FACTOR -> num (20)       ‚Üí atributo: 20
TERM -> FACTOR           ‚Üí atributo: 20
EXPR' -> OP TERM EXPR'   ‚Üí atributo: {"op": "+", "right": 20}
OP -> -                  ‚Üí atributo: "-"
FACTOR -> num (5)        ‚Üí atributo: 5
TERM -> FACTOR           ‚Üí atributo: 5
EXPR' -> OP TERM EXPR'   ‚Üí atributo: {"op": "-", "right": 5}
EXPR -> TERM EXPR'       ‚Üí atributo: "(10 + (20 - 5))"
```

**Valor Final:** `result = "(10 + (20 - 5))"` (representa√ß√£o da express√£o)

### Exemplo 7: Pipeline Completo com PDA

**C√≥digo:**
```fantasy
KEL dragon # FUS health := 500 # JUN health
```

**Sa√≠da Completa:**
```
==================================================================
=          SA√çDA DO PDA (Compiladores/main.py)                  =
==================================================================

 Processando entrada no PDA...
Entrada: KEL dragon # FUS health := 500 # JUN health

[OK] Linha 1: 'KEL' -> Estado E11,Z -> KEL (ACEITO)
  Linha 1: 'dragon' -> N√£o reconhecido pelo PDA -> id
[OK] Linha 2: 'FUS' -> Estado D5,Z -> FUS (ACEITO)
  Linha 2: 'health' -> N√£o reconhecido pelo PDA -> id
  Linha 2: ':=' -> N√£o reconhecido pelo PDA -> :=
  Linha 2: '500' -> N√£o reconhecido pelo PDA -> num
[OK] Linha 3: 'JUN' -> Estado D4,Z -> JUN (ACEITO)
  Linha 3: 'health' -> N√£o reconhecido pelo PDA -> id

==================================================================
 TABELA DE S√çMBOLOS DO PDA:
==================================================================
Linha    Palavra         Estado Final    Status    
==================================================================
1        KEL             E11,Z           [OK] ACEITO
1        dragon          X               [X] REJEITADO
2        FUS             D5,Z            [OK] ACEITO
2        health          X               [X] REJEITADO
...

[OK] PDA processou 7 palavras
[OK] Gerados 8 tokens (incluindo EOF)

==================================================================
=              TOKENS GERADOS PARA O PARSER                      =
==================================================================
  1. Token(KEL, 'KEL', L1)
  2. Token(id, 'dragon', L1)
  3. Token(FUS, 'FUS', L2)
  4. Token(id, 'health', L2)
  5. Token(:=, ':=', L2)
  6. Token(num, '500', L2)
  7. Token(JUN, 'JUN', L3)
  8. Token(id, 'health', L3)

================================================================================
FASE 2 & 3: AN√ÅLISE SINT√ÅTICA E SEM√ÇNTICA (SLR)
================================================================================

=== Analise Sintatica e Semantica SLR(1) ===

[Sem√¢ntico] Definindo m√≥dulo 'dragon' (linha 1)
[Sem√¢ntico] Declarando 'health' = 500 (linha 2)
[Sem√¢ntico] I/O com 'health' (linha 3)

[OK] ANALISE SINTATICA ACEITA!

======================================================================
RELATORIO DE ANALISE
======================================================================

[OK] Nenhum erro encontrado

======================================================================
TABELA DE SIMBOLOS
======================================================================
Escopo: global
  [‚úì] dragon: module
  Escopo: KEL_dragon
    [‚úì] health: variable
======================================================================
```

---

## üìñ Gram√°tica da Linguagem

### Produ√ß√µes BNF

```bnf
S ::= CMD ; S
    | CMD

CMD ::= LOS EXPR CMD                    # if
     | FOD CMD FAH EXPR                 # while
     | FAH CMD FAH EXPR                 # for
     | IO id                            # input/output
     | JUN EXPR                         # return
     | LHS := EXPR                      # atribui√ß√£o
     | KEL id CMD                       # m√≥dulo
     | FUS id := EXPR                   # declara√ß√£o

IO ::= HON | print

LHS ::= assign id
      | HIM . id

EXPR ::= TERM EXPR'

EXPR' ::= OP TERM EXPR'
        | Œµ

OP ::= + | - | ANRK | AAN | KO

TERM ::= UNARY | FACTOR

UNARY ::= NUST TERM

FACTOR ::= id
         | num
         | HIM . id
         | ( EXPR )
```

### Conjuntos FIRST e FOLLOW

**FIRST:**
```
FIRST(S) = {LOS, FOD, FAH, JUN, KEL, FUS, HON, print, assign, HIM}
FIRST(EXPR) = {NUST, id, num, HIM, (}
FIRST(EXPR') = {Œµ, +, -, ANRK, AAN, KO}
FIRST(TERM) = {NUST, id, num, HIM, (}
FIRST(FACTOR) = {id, num, HIM, (}
```

**FOLLOW:**
```
FOLLOW(S) = {$}
FOLLOW(CMD) = {;, $, FAH}
FOLLOW(EXPR) = {LOS, FOD, FAH, JUN, KEL, ;, $, )}
FOLLOW(EXPR') = {LOS, FOD, FAH, JUN, KEL, ;, $, )}
FOLLOW(TERM) = {+, -, ANRK, AAN, KO, ...}
FOLLOW(FACTOR) = {+, -, ANRK, AAN, KO, ...}
```

---

## üöÄ Como Usar

### Instala√ß√£o
```powershell
# Clonar reposit√≥rio
git clone <repo-url>
cd "Analisador Sintatico"
```

### Uso B√°sico

#### 1. An√°lise L√©xica Apenas
```python
from lexer import Lexer

code = "FUS health := 100"
lexer = Lexer(code)
tokens = lexer.tokenize()
lexer.print_tokens()
```

#### 2. Compila√ß√£o Completa
```python
from main import CompiladorCompleto

compilador = CompiladorCompleto(verbose=True)
code = "FUS x := 10 ; JUN x"
sucesso = compilador.compile(code)
```

#### 3. Parser Direto (sem PDA)
```python
from lexer import Lexer
from parser_integrated import SLRParserWithSemantics, Token

lexer = Lexer("FUS x := 10")
tokens = lexer.tokenize()

parser = SLRParserWithSemantics(verbose=True)
sucesso = parser.parse(tokens)
parser.print_report()
```

### Executar Exemplos
```powershell
# Exemplos do lexer
python lexer.py

# Exemplos do parser
python parser_integrated.py

# Compilador completo
python main.py

# Testes de sem√¢ntica
python teste_semantica.py
```

---

## üß™ Casos de Teste

### Teste 1: Declara√ß√£o V√°lida ‚úì
```fantasy
FUS health := 100
```
**Esperado:** Aceito, `health` declarado com valor 100

### Teste 2: Erro Sint√°tico ‚úó
```fantasy
FUS x 10
```
**Esperado:** Erro - falta operador `:=`

### Teste 3: Erro Sem√¢ntico ‚úó
```fantasy
assign y := 50
```
**Esperado:** Erro - `y` n√£o foi declarado

### Teste 4: Programa Complexo ‚úì
```fantasy
KEL player FUS health := 100 ; FUS mana := 50 ; assign health := health - 10
```
**Esperado:** Aceito
- M√≥dulo `player` criado
- Vari√°veis `health` e `mana` declaradas
- `health` atualizado para 90

### Teste 5: Aviso - Vari√°vel N√£o Usada ‚ö†
```fantasy
FUS unused := 0 ; FUS x := 10 ; JUN x
```
**Esperado:** Aviso - `unused` declarado mas n√£o usado

---

## üõ†Ô∏è Estrutura de Arquivos

```
Analisador Sintatico/
‚îÇ
‚îú‚îÄ‚îÄ lexer.py                    # Analisador l√©xico
‚îú‚îÄ‚îÄ parser_integrated.py        # Parser SLR(1) + sem√¢ntica
‚îú‚îÄ‚îÄ symbol_table.py             # Tabela de s√≠mbolos
‚îú‚îÄ‚îÄ main.py                     # Pipeline PDA + SLR
‚îú‚îÄ‚îÄ SLR.py                      # Closures LR(0)
‚îú‚îÄ‚îÄ goto.py                     # Tabela de transi√ß√µes
‚îú‚îÄ‚îÄ first.py                    # Conjuntos FIRST
‚îú‚îÄ‚îÄ follow.py                   # Conjuntos FOLLOW
‚îú‚îÄ‚îÄ terminais.py                # S√≠mbolos terminais
‚îú‚îÄ‚îÄ nao_terminais.py            # S√≠mbolos n√£o-terminais
‚îú‚îÄ‚îÄ regrasSint√°ticas.txt        # Gram√°tica BNF
‚îú‚îÄ‚îÄ teste_semantica.py          # Suite de testes
‚îÇ
‚îî‚îÄ‚îÄ Compiladores/
    ‚îú‚îÄ‚îÄ pda.py                  # Aut√¥mato de pilha
    ‚îú‚îÄ‚îÄ delta.py                # Transi√ß√µes do PDA
    ‚îú‚îÄ‚îÄ constants.py            # Constantes (EPSILON)
    ‚îî‚îÄ‚îÄ main.py                 # Execut√°vel do PDA
```

---

## üìö Refer√™ncias

- **Compiladores: Princ√≠pios, T√©cnicas e Ferramentas** (Aho, Sethi, Ullman)
- **Modern Compiler Implementation** (Appel)
- **SLR Parsing:** Simple LR Parser
- **An√°lise Sint√°tica Bottom-Up:** Shift-Reduce Parsing

---

## üë• Contribuidores

Projeto desenvolvido como parte do curso de Compiladores.

---

## üìÑ Licen√ßa

Este projeto √© de c√≥digo aberto para fins educacionais.

---

**√öltima atualiza√ß√£o:** 02/12/2025
